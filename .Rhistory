# temp <- bss_val %>% filter(sku == "File Folders SKU 47")
initial_guess <- median(bss_val$price, na.rm = TRUE)
lower_limit <- bss_val$min_price
upper_limit <- bss_val$max_price
profit_function <- function(price, model, df) {
predicted_volume <- predict(model, newdata = transform(df, price = price), re.form = NA)
profit <- price * predicted_volume - df$cost
return(-sum(profit, na.rm = TRUE))
}
result <- optim(
par = initial_guess,
fn = profit_function,
model = bss_hierachical_price_product_intercept,
df = bss_val,
method = "L-BFGS-B",
lower = lower_limit,
upper = upper_limit
)
View(bss_val)
t <- result$par
t
initial_guess <- median(bss_val$price, na.rm = TRUE)
lower_limit <- min(bss_val$price, na.rm = TRUE)
upper_limit <- max(bss_val$price, na.rm = TRUE)
profit_function <- function(price, model, df) {
predicted_volume <- predict(model, newdata = transform(df, price = price), re.form = NA)
profit <- price * predicted_volume - df$cost
return(-sum(profit, na.rm = TRUE))
}
result <- optim(
par = initial_guess,
fn = profit_function,
model = bss_hierachical_price_product_intercept,
df = bss_val,
method = "L-BFGS-B",
lower = lower_limit,
upper = upper_limit
)
t <- result$par
t
initial_guess <- bss_val$min_price
lower_limit <- min(bss_val$price, na.rm = TRUE)
upper_limit <- max(bss_val$price, na.rm = TRUE)
profit_function <- function(price, model, df) {
predicted_volume <- predict(model, newdata = transform(df, price = price), re.form = NA)
profit <- price * predicted_volume - df$cost
return(-sum(profit, na.rm = TRUE))
}
result <- optim(
par = initial_guess,
fn = profit_function,
model = bss_hierachical_price_product_intercept,
df = bss_val,
method = "L-BFGS-B",
lower = lower_limit,
upper = upper_limit
)
t <- result$par
t
initial_guess <- min(bss_val$min_price)
lower_limit <- min(bss_val$price, na.rm = TRUE)
upper_limit <- max(bss_val$price, na.rm = TRUE)
profit_function <- function(price, model, df) {
predicted_volume <- predict(model, newdata = transform(df, price = price), re.form = NA)
profit <- price * predicted_volume - df$cost
return(-sum(profit, na.rm = TRUE))
}
result <- optim(
par = initial_guess,
fn = profit_function,
model = bss_hierachical_price_product_intercept,
df = bss_val,
method = "L-BFGS-B",
lower = lower_limit,
upper = upper_limit
)
t <- result$par
t
temp <- bss_val
temp <- data.frame()
x <- colnames(bss_bkp)
temp <- temp[, x]
temp <- bss_bkp[FALSE,]
glimpse(temp)
rm(temp)
temp <- bss_val %>% filter(salesdate == "2023-09-09")
temp <- bss_val %>% filter(salesdate > "2023-08-29" & salesdate <= "2023-09-09")
View(temp)
temp$salesdate <- seq(from = as.Date("2023-09-10"), to = as.Date("2023-09-18"), by = "day")
temp <- temp[(-nrow(temp) - 1):nrow(temp),]
temp <- temp[(-nrow(temp) - 2):nrow(temp),]
temp <- temp[(-nrow(temp)):nrow(temp),]
temp <- temp[(-nrow(temp)-1):nrow(temp),]
temp <- temp[(nrow(temp)-1):nrow(temp),]
temp <- bss_val %>% filter(salesdate > "2023-08-29" & salesdate <= "2023-09-09")
temp <- temp[(1- nrow(temp)):nrow(temp),]
temp <- temp[-(nrow(temp)-1):nrow(temp),]
temp <- temp[(-nrow(temp)-1):nrow(temp),]
# Remove the last two rows only if the data frame has more than two rows
if (nrow(temp) > 2) {
temp <- temp[-((nrow(temp) - 1):(nrow(temp))), ]
} else {
# Handle the case where you have two or fewer rows
warning("Data frame has two or fewer rows. Cannot remove last two rows.")
}
temp$salesdate <- seq(from = as.Date("2023-09-10"), to = as.Date("2023-09-18"), by = "day")
temp$price <- t
temp$pred_vol <- predict(bss_hierachical_price_product_intercept, newdata = temp, re.form = NA)
temp$pred_profit <- (temp$price * temp$pred_vol) - temp$cost
p <- mape(temp$profit, temp$pred_profit)
print(paste0("Profit MAPE: ", p, "%"))
temp <- bss_val %>% filter(salesdate > "2023-08-29" & salesdate <= "2023-09-09")
# Remove the last two rows
if (nrow(temp) > 2) {
temp <- temp[-((nrow(temp) - 1):(nrow(temp))), ]
} else {
# Handle the case where you have two or fewer rows
warning("Data frame has two or fewer rows. Cannot remove last two rows.")
}
temp$salesdate <- seq(from = as.Date("2023-09-10"), to = as.Date("2023-09-18"), by = "day")
temp$weekday <- wday(temp$salesdate, label = TRUE) # Introduce a weekday instrumental variable
temp$price <- t
temp$pred_vol <- predict(bss_hierachical_price_product_intercept, newdata = temp, re.form = NA)
temp$pred_profit <- (temp$price * temp$pred_vol) - temp$cost
p <- mape(temp$profit, temp$pred_profit)
print(paste0("Profit MAPE: ", p, "%"))
temp$pred_vol <- round(predict(bss_hierachical_price_product_intercept, newdata = temp, re.form = NA),0)
cat("\f") # Clear Console
rm(list = ls()) # Clear the working environment
# Import the requisite libraries
options(show.message = FALSE) # Suppress package startup messages
library("tidyverse") # for tidy data
library("car") # for regression
library("broom")
library("lubridate") # for working with date/time-stamp records
library("tseries") # for working with time-series data
library("forecast") # for working with time-series data
library("ggplot2") # for visualization
library("ggfortify") # For Visualization
library("lme4") # For building Hierarchical/Mixed-Effect Models
library("merTools")
setwd("C:/Users/anubh/Desktop/Anubhav Shankar/Additional Education/INFORMS/BSS Competition")
getwd()
bss <- read.csv("competition_training_data.csv") # Ingest the data set
# Create a backup of the data frame
bss_bkp <- bss
# Visualize the metadata
str(bss)
max(bss$salesdate)
min(bss$salesdate)
length(unique(bss$sku))
# Function to change all integer types to double
change_to_dbl <- function(df) {
df %>% mutate_at(vars(which(sapply(df, is.integer))), as.double)
}
bss <- change_to_dbl(bss)
head(bss) # Get a pivot of the first few rows
summary(bss) # Get a basic data summary
# Rename the requisite columns
bss <- bss %>% rename("volume" = "unitsordered")
bss <- bss %>% rename("revenue" = "sales")
bss <- bss %>% rename("stock" = "managed_fba_stock_level")
is_na_count <- bss %>% summarize_all(funs(sum(is.na(.)))) # Check the NA's in each field
is_na_count
bss_rc_missing <- bss %>% summarise(across(where(is.numeric), ~sum(is.na(.x)))) %>% t() %>% as.data.frame()
bss_rc_nomiss <- bss %>% summarise(across(where(is.numeric), ~sum(!is.na(.x)))) %>% t() %>% as.data.frame()
bss$prod_cat <- trimws(gsub("SKU \\d+", "",bss$sku)) # Extract the unique product categories
# Change the requisite columns to factors for the Hierarchical Model
bss <- bss %>% mutate(prod_cat = as.factor(prod_cat),
sku = as.factor(sku))
# Get the number of competitors for each product code
# A vector of all competitor price columns
comp_price_cols_n <- grep("comp_[0-9]+_price", colnames(bss), value = TRUE)
comp_price_cols <- grep("_price",colnames(bss),value = TRUE)
price_cols <- c("price",comp_price_cols_n) # Create a vector of BSS & Competitor price columns
bss$competitor_count <- rowSums(!is.na(bss[, comp_price_cols_n])) # Get the number of competitors for each product
# rowSums() in the above command is counting the number of columns that doesn't have a NA value for a particular row
# Verify to see if the competitor counts match the problem document
comp_count_verification <- bss %>%
group_by(sku) %>%
summarise(unique_competitor_count = unique(competitor_count)) %>%
group_by(unique_competitor_count) %>%
summarise(num_of_items = n()) %>%
arrange(unique_competitor_count)
comp_count_verification
# Visualize the competition
bss_temp <- bss %>% dplyr::select(prod_cat, price, all_of(comp_price_cols),competitor_count) %>% group_by(prod_cat)
total_competitors_by_product <- aggregate(bss_temp$competitor_count, by=list(product_name=bss_temp$prod_cat), FUN=max)
colnames(total_competitors_by_product)[2] <- "competitors" # Rename the second element of the list; 'x' by default
ggplot(total_competitors_by_product,aes(x=product_name, y=competitors)) +
geom_bar(stat = "identity", fill = "steelblue") +
# geom_smooth(aes(group=1), method="loess", color="red", se=FALSE) +
geom_text(aes(label = competitors), vjust = -0.5) +
labs(title = "Max No. of Competitors by Product",
x = "Product",
y = "No. of Competitors") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1.2, size = 8)) # Rotate the axis labels to make them more legible
max_prices_by_product <- bss %>%
dplyr::select(sku, all_of(price_cols)) %>%
group_by(sku) %>%
summarise(across(all_of(price_cols),
~ ifelse(all(is.na(.)), NA, max(., na.rm = TRUE)),
.names = "max_{.col}"))
min_prices_by_product <- bss %>%
dplyr::select(sku, all_of(price_cols)) %>%
group_by(sku) %>%
summarise(across(all_of(price_cols),
~ ifelse(all(is.na(.)), NA, min(., na.rm = TRUE)),
.names = "min_{.col}"))
# Merge all the costs together
bss$cost <- 0.0
bss$cost <- bss$cogs + bss$fba + bss$reffee + bss$adspend
# Do the necessary date operations
bss$salesdate <- as.Date(bss$salesdate,"%Y-%m-%d") # Coerce the 'salesdate' into Date type
bss$quarter <- as.factor(paste0("Q",quarter(bss$salesdate))) # Extract the Quarter from the date
bss$month <- month(bss$salesdate, label = TRUE, abbr = TRUE) # Extract the month from the date
bss$weekday <- factor(wday(bss$salesdate, label = TRUE), ordered = FALSE) # Introduce a weekday instrumental variable
bss <- bss %>% group_by(sku) %>% mutate(days_sold = round(as.numeric(difftime(max(salesdate), min(salesdate), units = "days")))) # Calculate the duration for which a good has been sold
bss <- bss %>% group_by(sku) %>% mutate(first_sell = min(salesdate)) # First instance of the good sold
bss <- bss %>% group_by(sku) %>% mutate(last_sell = max(salesdate)) # Latest instance of the good sold
length(unique(bss$first_sell)) # See the different starting dates
length(unique(bss$last_sell)) # See the different latest sell dates for products
# Create a histogram to see the spread of the 'price' field
ggplot(bss, aes(x = price)) +
geom_histogram(aes(y = after_stat(density)), binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
geom_density(color = "red", linewidth = 1) + # plot a superimposing density curve
theme_minimal() +
labs(title = "Distribution of Price", x = "Price", y = "Density")
# Create a histogram to see the spread of the 'cost' field
ggplot(bss, aes(x = cost)) +
# geom_histogram(aes(y = after_stat(density)),binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
geom_histogram(binwidth = 10, fill = "blue", color = "black", alpha = 0.7) +
theme_minimal() +
labs(title = "Distribution of Cost", x = "Cost", y = "Count")
# Create a boxplot to see the outliers in the 'price' field
ggplot(bss, aes(y = price)) +
geom_boxplot(fill = "lightblue", color = "black") +
theme_minimal() +
labs(title = "Boxplot of Price", y = "Price")
# Attempt to visualize the sales function
plot(bss$price,bss$volume)
ggplot(bss, aes(x = price, y = volume)) +
geom_line() +
labs(title = "Sales Function", x = "Price", y = "Volume") +
theme_minimal()
# Create a boxplot to see the outliers in the 'cost' field
ggplot(bss, aes(y = cost)) +
geom_boxplot(fill = "lightblue", color = "black") +
theme_minimal() +
labs(title = "Boxplot of Cost", y = "Price")
# Let's see the distribution of all the price variables
# Convert data to long format
bss_long <- bss %>%
pivot_longer(cols = contains("_price"), # A regex operation
names_to = "Price_Variable",
values_to = "Price_Value",
values_drop_na = TRUE)
# Plot using ggplot2
ggplot(bss_long, aes(x = Price_Value)) +
geom_histogram(fill = "blue", color = "black", alpha = 0.7, bins = 10) +
facet_wrap(~Price_Variable, scales = "free_y") + # Customize each plot basis it's respective range
theme_minimal() +
labs(title = "Distribution of Price Variables", x = "Price", y = "Count")
# Check the distribution of the 'volume' field
weekday_totals <- aggregate(bss$volume, by=list(weekday=bss$weekday), FUN=sum)
colnames(weekday_totals)[2] <- "volume"
ggplot(weekday_totals,aes(x=weekday, y=volume)) +
geom_bar(stat = "identity", fill = "steelblue") +
geom_smooth(aes(group=1), method="loess", color="red", se=FALSE) +
geom_text(aes(label = volume), vjust = -0.5) +
labs(title = "Volume sold by Weekday",
x = "Weekday",
y = "Volume") +
theme_minimal()
# Check the distribution of the volume sold by the Product
product_totals <- aggregate(bss$volume, by=list(product_name=bss$prod_cat), FUN=sum)
colnames(product_totals)[2] <- "volume" # Rename the second element of the list; 'x' by default
ggplot(product_totals,aes(x=product_name, y=volume)) +
geom_bar(stat = "identity", fill = "steelblue") +
# geom_smooth(aes(group=1), method="loess", color="red", se=FALSE) +
geom_text(aes(label = volume), vjust = -0.5) +
labs(title = "Volume sold by Product",
x = "Product",
y = "Volume") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1.2, size = 8)) # Rotate the axis labels to make them more legible
bss_pivot <- bss %>% filter(salesdate >= "2022-01-01" & salesdate <= "2022-07-13") %>% dplyr::select(sku, price, volume, prod_cat) %>% distinct()
# product_name <- c("File Folders SKU 47","File Folders SKU 20")
product_name <- c("File Folders SKU 47")
bss_pivot %>% filter(sku %in% product_name) %>%
ggplot(aes(x = price, y = volume, color = sku)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
labs(title = "Price vs Volume for Selected Product",
x = "Price",
y = "Volume",
color = "Product") +
theme_minimal()
product_category <- c("File Folders", "Classification Folders")
bss_pivot %>% filter(prod_cat %in% product_category) %>%
ggplot(aes(x = price, y = volume, color = prod_cat)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
labs(title = "Price vs Volume for File Folders",
x = "Price",
y = "Volume",
color = "Product") +
theme_minimal()
bss_pivot <- bss %>% filter(salesdate >= "2022-01-01" & salesdate <= "2022-07-13") %>% dplyr::select(sku, price, revenue, prod_cat) %>% distinct()
product_name <- c("File Folders SKU 47")
bss_pivot %>% filter(sku %in% product_name) %>%
ggplot(aes(x = price, y = revenue, color = sku)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
labs(title = "Price vs Revenue for Selected Product",
x = "Price",
y = "Revenue",
color = "Product") +
theme_minimal()
# Filter for data in 2022
recent_profit <- bss %>%
filter(year(salesdate) == 2022) %>%
# Group by quarter and summarize the profit
group_by(Qtr = quarter) %>%
summarise(Total_Profit = sum(profit, na.rm = TRUE)) %>%
ungroup()
# Convert the data to a time series object
profit_ts <- ts(recent_profit$Total_Profit, start = c(2022,1), frequency = 4)
# Plot
autoplot(profit_ts) + labs(y ="Profit Earned", title = "Quarterly Profits for 2022")
recent_sales <- bss %>%
filter(year(salesdate) == 2022) %>%
# Group by quarter and summarize the sales
group_by(Qtr = quarter) %>%
summarise(Total_Sales = sum(volume, na.rm = TRUE)) %>%
ungroup()
sales_ts <- ts(recent_sales$Total_Sales, start = c(2022,1), frequency = 4)
autoplot(sales_ts) + labs(y ="Volume Sold", title = "Quarterly Sales for 2022")
monthly_sales <- bss %>%
filter(year(salesdate) == 2022) %>%
# Group by quarter and summarize the sales
group_by(Month = month) %>%
summarise(Total_Sales_m = sum(volume, na.rm = TRUE)) %>%
ungroup()
monthly_sales_ts <- ts(monthly_sales$Total_Sales_m, start = c(2022,1), frequency = 12)
autoplot(monthly_sales_ts) + labs(y ="Volume Sold", title = "Monthly Sales for 2022")
# Scale all the price columns with the competitor & market thresholds
bss <- bss %>%
mutate(
across(all_of(price_cols),
~ ifelse(is.infinite(round((. - min_price) / (max_price - min_price),2)),
NA,
round((. - min_price) / (max_price - min_price),2)),
.names = "{.col}_scaled_m"),
across(all_of(price_cols),
~ ifelse(is.infinite(round((. - comp_data_min_price) / (comp_data_max_price - comp_data_min_price),2)),
NA,
round((. - comp_data_min_price) / (comp_data_max_price - comp_data_min_price),2)),
.names = "{.col}_scaled_c")
)
glimpse(bss)
seed <- 123
set.seed(seed = seed) # Set seed for reproducability
# Function to calculate the Mean Absolute Percentage Error
mape <- function(actual,forecast){
valid_rows <- which(actual != 0 & !is.na(actual) & !is.na(forecast))
actual <- actual[valid_rows]
forecast <- forecast[valid_rows]
n <- length(actual)
if(n==0){
return (NA)
}
val <- sum(abs((actual - forecast)/actual))/n * 100
return(round(val,2))
}
# Function to round the price to $0.05 or $0.09
round_to_constraint <- function(x){
integer_part <- floor(x)
decimal_part <- x - integer_part
if(decimal_part < 0.05){
return(integer_part + 0.05)
}
else if(decimal_part < 0.09){
return(integer_part + 0.09)
}
else{
return(integer_part + 0.05 + 1)
}
}
bss_train <- bss %>% filter(sku != "File Folders SKU 47") # Create the training set
bss_val <- bss %>% filter(sku == "File Folders SKU 47") # Create the validation set
glimpse(bss_train)
glimpse(bss_val)
bss_hierachical_price_product_intercept <- lmer(volume ~ 1 + comp_1_price + comp_2_price + cost + I(price - cost) + salesdate + weekday + (1 + cost | sku), data = bss_train, REML = TRUE)
ranef(bss_hierachical_price_product_intercept)
plot(ranef(bss_hierachical_price_product_intercept))
summary(bss_hierachical_price_product_intercept)
predictions <- predict(bss_hierachical_price_product_intercept, newdata = bss_val)
bss_train <- bss %>% filter(salesdate <= "2023-05-31") # Create the training set
bss_val <- bss %>% filter(salesdate >= "2023-06-01" & sku == "File Folders SKU 47") # Create the validation set
glimpse(bss_train)
glimpse(bss_val)
bss_hierachical_price_product_intercept <- lmer(volume ~ 1 + comp_1_price + comp_2_price + cost + I(price - cost) + salesdate + weekday + (1 + cost | sku), data = bss_train, REML = TRUE)
ranef(bss_hierachical_price_product_intercept)
plot(ranef(bss_hierachical_price_product_intercept))
summary(bss_hierachical_price_product_intercept)
predictions <- predict(bss_hierachical_price_product_intercept, newdata = bss_val)
bss_val$pred_vol <- round(predictions,0)
View(bss_val)
initial_guess <- median(bss_val$price, na.rm = TRUE)
lower_limit <- min(bss_val$price, na.rm = TRUE)
upper_limit <- max(bss_val$price, na.rm = TRUE)
profit_function <- function(price, model, df) {
predicted_volume <- predict(model, newdata = transform(df, price = price), re.form = NA)
profit <- price * predicted_volume - df$cost
return(-sum(profit, na.rm = TRUE))
}
result <- optim(
par = initial_guess,
fn = profit_function,
model = bss_hierachical_price_product_intercept,
df = bss_val,
method = "L-BFGS-B",
lower = lower_limit,
upper = upper_limit
)
t <- result$par
t
profit_function <- function(price, model, df) {
predicted_volume <- predict(model, newdata = transform(df, price = price))
profit <- price * predicted_volume - df$cost
return(-sum(profit, na.rm = TRUE))
}
result <- optim(
par = initial_guess,
fn = profit_function,
model = bss_hierachical_price_product_intercept,
df = bss_val,
method = "L-BFGS-B",
lower = lower_limit,
upper = upper_limit
)
t <- result$par
t
temp <- bss_val %>% filter(salesdate > "2023-08-29" & salesdate <= "2023-09-09")
# Remove the last two rows
if (nrow(temp) > 2) {
temp <- temp[-((nrow(temp) - 1):(nrow(temp))), ]
} else {
# Handle the case where you have two or fewer rows
warning("Data frame has two or fewer rows. Cannot remove last two rows.")
}
temp$salesdate <- seq(from = as.Date("2023-09-10"), to = as.Date("2023-09-18"), by = "day")
temp$weekday <- wday(temp$salesdate, label = TRUE) # Introduce a weekday instrumental variable
temp$price <- t
temp$pred_vol <- round(predict(bss_hierachical_price_product_intercept, newdata = temp, re.form = NA),0)
temp$pred_profit <- (temp$price * temp$pred_vol) - temp$cost
p <- mape(temp$profit, temp$pred_profit)
print(paste0("Profit MAPE: ", p, "%"))
View(temp)
cat("\f") # Clear Console
rm(list = ls()) # Clear the working environment
cat("\f") # Clear Console
rm(list = ls()) # Clear the working environment
# Import the requisite libraries
options(show.message = FALSE) # Suppress package startup messages
library("tidyverse") # for tidy data
library("car") # for regression
library("broom")
library("lubridate") # for working with date/time-stamp records
library("tseries") # for working with time-series data
library("forecast") # for working with time-series data
library("ggplot2") # for visualization
library("ggfortify") # For Visualization
library("lme4") # For building Hierarchical/Mixed-Effect Models
library("merTools")
# setwd("C:/Users/anubh/Desktop/Anubhav Shankar/Additional Education/INFORMS/BSS-Competition")
# getwd()
bss <- read.csv(url("https://github.com/aAnubhav2147/BSS-Competition/blob/main/Archive/Archived%20Datasets/competition_training_data.csv")) # Ingest the data set
# Create a backup of the data frame
bss_bkp <- bss
# Visualize the metadata
str(bss)
max(bss$salesdate)
min(bss$salesdate)
length(unique(bss$sku))
cat("\f") # Clear Console
rm(list = ls()) # Clear the working environment
# Import the requisite libraries
options(show.message = FALSE) # Suppress package startup messages
library("tidyverse") # for tidy data
library("car") # for regression
library("broom")
library("lubridate") # for working with date/time-stamp records
library("tseries") # for working with time-series data
library("forecast") # for working with time-series data
library("ggplot2") # for visualization
library("ggfortify") # For Visualization
library("lme4") # For building Hierarchical/Mixed-Effect Models
library("merTools")
# setwd("C:/Users/anubh/Desktop/Anubhav Shankar/Additional Education/INFORMS/BSS-Competition")
# getwd()
bss <- read.csv("https://github.com/aAnubhav2147/BSS-Competition/blob/main/Archive/Archived%20Datasets/competition_training_data.csv") # Ingest the data set
# Create a backup of the data frame
bss_bkp <- bss
# Visualize the metadata
str(bss)
max(bss$salesdate)
min(bss$salesdate)
length(unique(bss$sku))
rm(list = ls()) # Clear the working environment
